name: sign_experiment
data:
    root_path: /home/rzhao/data/ts/GEFCOM/GEFCOM-2017-luo/gefcom2017.csv
    data: gefcom_reg
training:
    use_cuda: True
    random_seed: 42
    model_dir: "./debug"

    # optimizer and learning rate scheduler
    batch_size: 16
    epochs: 100
    batch_multiplier: 1
    optimization:
        optimizer: adam
        learning_rate: 0.0001
        scheduler: plateau  # plateau, onecycle, warmupexponentialdecay, cosineannealing
        learning_rate_warmup: 100
        learning_rate_min: 1.0e-07
        weight_decay: 0.001
        patience: 1
        decrease_factor: 0.7
        betas:
            - 0.9
            - 0.998
    # eval and logging
    eval_metric: mse  # ["bleu", "chrf", "wer", "rouge"]:
    early_stopping_metric: eval_metric
    num_valid_log: 5
    overwrite: true
    shuffle: true
    keep_last_ckpts: 1
    logging_freq: 100
    validation_freq: 100  #  valid on dev set
    validation_freq_epoch: 1  # valid on train set
model:
    initializer: xavier
    bias_initializer: zeros
    init_gain: 1.0
    embed_initializer: xavier
    embed_init_gain: 1.0
    tied_softmax: false
    seg_embeddings:
        embedding_dim: 256
        scale: false
        dropout: 0.1
        norm_type: batch
        activation_type: softsign
        num_heads: 8 # same as encoder/decoder?
    pos_encoding:
        size: 256
        max_len: 512
    encoder:
        type: transformer
        embeddings:
            embedding_dim: 512
            scale: false
            dropout: 0.1
            norm_type: batch
            activation_type: softsign
        num_layers: 3
        num_heads: 8
        hidden_size: 512
        ff_size: 2048
        dropout: 0.1
    decoder:
        type: transformer
        embeddings:
            embedding_dim: 512
            scale: false
            dropout: 0.1
            norm_type: batch
            activation_type: softsign
        num_layers: 3
        num_heads: 8
        hidden_size: 512
        ff_size: 2048
        dropout: 0.1
